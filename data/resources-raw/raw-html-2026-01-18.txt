<!doctype html>
<html lang="en" class="no-js" data-header-style="classic">

<head>
    <title>Context Engineering</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <script>document.documentElement.classList.replace('no-js','js');</script>
    <script>
        if (window.localStorage.getItem('kutak-prefers-color-scheme') && !document.documentElement.hasAttribute('data-prefers-color-scheme')) {
            document.documentElement.setAttribute('data-prefers-color-scheme', window.localStorage.getItem('kutak-prefers-color-scheme'));
        }
    </script>

    <link rel="preload" as="font" type="font/woff2" href="https://www.blog.langchain.com/assets/fonts/source-sans-pro-v21-latin-ext_latin-regular.woff2?v=b17a0306be" crossorigin>
<link rel="preload" as="font" type="font/woff2" href="https://www.blog.langchain.com/assets/fonts/source-sans-pro-v21-latin-ext_latin-600.woff2?v=b17a0306be" crossorigin>
<link rel="preload" as="font" type="font/woff2" href="https://www.blog.langchain.com/assets/fonts/source-sans-pro-v21-latin-ext_latin-700.woff2?v=b17a0306be" crossorigin>

<style>
    @font-face {
        font-family: 'Source Sans Pro';
        font-style: normal;
        font-weight: 400;
        font-display: swap;
        src: url('https://www.blog.langchain.com/assets/fonts/source-sans-pro-v21-latin-ext_latin-regular.woff2?v=b17a0306be') format('woff2');
    }

    @font-face {
        font-family: 'Source Sans Pro';
        font-style: italic;
        font-weight: 400;
        font-display: swap;
        src: url('https://www.blog.langchain.com/assets/fonts/source-sans-pro-v21-latin-ext_latin-italic.woff2?v=b17a0306be') format('woff2');
    }

    @font-face {
        font-family: 'Source Sans Pro';
        font-style: normal;
        font-weight: 600;
        font-display: swap;
        src: url('https://www.blog.langchain.com/assets/fonts/source-sans-pro-v21-latin-ext_latin-600.woff2?v=b17a0306be') format('woff2');
    }

    @font-face {
        font-family: 'Source Sans Pro';
        font-style: italic;
        font-weight: 600;
        font-display: swap;
        src: url('https://www.blog.langchain.com/assets/fonts/source-sans-pro-v21-latin-ext_latin-600italic.woff2?v=b17a0306be') format('woff2');
    }

    @font-face {
        font-family: 'Source Sans Pro';
        font-style: normal;
        font-weight: 700;
        font-display: swap;
        src: url('https://www.blog.langchain.com/assets/fonts/source-sans-pro-v21-latin-ext_latin-700.woff2?v=b17a0306be') format('woff2');
    }

    @font-face {
        font-family: 'Source Sans Pro';
        font-style: italic;
        font-weight: 700;
        font-display: swap;
        src: url('https://www.blog.langchain.com/assets/fonts/source-sans-pro-v21-latin-ext_latin-700italic.woff2?v=b17a0306be') format('woff2');
    }

    :root {
        --kutak--font-family--base: 'Source Sans Pro', Helvetica, sans-serif;
        --kutak--font-family--headings: 'Source Sans Pro', Helvetica, sans-serif;
        --kutak--font-family--elements: 'Source Sans Pro', Helvetica, sans-serif;
        --kutak--font-weight--base: 400;
        --kutak--font-weight--base-bold: 700;
        --kutak--font-weight--headings: 700;
        --kutak--font-weight--headings-small: 600;
        --kutak--font-weight--elements: 600;
    }
</style>

    <link rel="stylesheet" href="https://www.blog.langchain.com/assets/dist/style.css?v=b17a0306be">

                <link rel="preload" as="image"
                imagesrcset="/content/images/size/w360/format/webp/2025/10/Context-Engineering.png 360w,/content/images/size/w480/format/webp/2025/10/Context-Engineering.png 480w,/content/images/size/w760/format/webp/2025/10/Context-Engineering.png 760w,/content/images/size/w990/format/webp/2025/10/Context-Engineering.png 990w,/content/images/size/w1248/format/webp/2025/10/Context-Engineering.png 1248w,/content/images/size/w1520/format/webp/2025/10/Context-Engineering.png 1520w"
                imagesizes="(min-width: 1280px) 580px, (min-width: 1000px) calc(50vw - 60px), 100vw">


    <link rel="icon" href="https://www.blog.langchain.com/content/images/size/w256h256/2024/03/Twitter_ProfilePicture.png" type="image/png">
    <link rel="canonical" href="https://www.blog.langchain.com/context-engineering-for-agents/">
    <meta name="referrer" content="no-referrer-when-downgrade">
    
    <meta property="og:site_name" content="LangChain Blog">
    <meta property="og:type" content="article">
    <meta property="og:title" content="Context Engineering">
    <meta property="og:description" content="TL;DR

Agents need context to perform tasks. Context engineering is the art and science of filling the context window with just the right information at each step of an agent’s trajectory. In this post, we break down some common strategies — write, select, compress, and isolate — for context engineering">
    <meta property="og:url" content="https://www.blog.langchain.com/context-engineering-for-agents/">
    <meta property="og:image" content="https://www.blog.langchain.com/content/images/size/w1200/2025/10/Context-Engineering.png">
    <meta property="article:published_time" content="2025-07-02T15:52:42.000Z">
    <meta property="article:modified_time" content="2025-10-19T22:23:05.000Z">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Context Engineering">
    <meta name="twitter:description" content="TL;DR

Agents need context to perform tasks. Context engineering is the art and science of filling the context window with just the right information at each step of an agent’s trajectory. In this post, we break down some common strategies — write, select, compress, and isolate — for context engineering">
    <meta name="twitter:url" content="https://www.blog.langchain.com/context-engineering-for-agents/">
    <meta name="twitter:image" content="https://www.blog.langchain.com/content/images/size/w1200/2025/10/Context-Engineering.png">
    <meta name="twitter:label1" content="Written by">
    <meta name="twitter:data1" content="LangChain Accounts">
    <meta name="twitter:site" content="@LangChainAI">
    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="899">
    
    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "publisher": {
        "@type": "Organization",
        "name": "LangChain Blog",
        "url": "https://www.blog.langchain.com/",
        "logo": {
            "@type": "ImageObject",
            "url": "https://www.blog.langchain.com/content/images/2024/03/LangChain-logo.png"
        }
    },
    "author": {
        "@type": "Person",
        "name": "LangChain Accounts",
        "url": "https://www.blog.langchain.com/author/langchain-accounts/",
        "sameAs": []
    },
    "headline": "Context Engineering",
    "url": "https://www.blog.langchain.com/context-engineering-for-agents/",
    "datePublished": "2025-07-02T15:52:42.000Z",
    "dateModified": "2025-10-19T22:23:05.000Z",
    "image": {
        "@type": "ImageObject",
        "url": "https://www.blog.langchain.com/content/images/size/w1200/2025/10/Context-Engineering.png",
        "width": 1200,
        "height": 899
    },
    "description": "TL;DR\n\nAgents need context to perform tasks. Context engineering is the art and science of filling the context window with just the right information at each step of an agent’s trajectory. In this post, we break down some common strategies — write, select, compress, and isolate — for context engineering by reviewing various popular agents and papers. We then explain how LangGraph is designed to support them!\n\nAlso, see our video on context engineering here.\n\n\nContext Engineering\n\nAs Andrej Karpa",
    "mainEntityOfPage": "https://www.blog.langchain.com/context-engineering-for-agents/"
}
    </script>

    <meta name="generator" content="Ghost 6.12">
    <link rel="alternate" type="application/rss+xml" title="LangChain Blog" href="https://www.blog.langchain.com/rss/">
    <script defer src="https://cdn.jsdelivr.net/ghost/portal@~2.56/umd/portal.min.js" data-i18n="true" data-ghost="https://www.blog.langchain.com/" data-key="e411fdfa6f54398669f416d1f0" data-api="https://langchain-blog.ghost.io/ghost/api/content/" data-locale="en" crossorigin="anonymous"></script><style id="gh-members-styles">.gh-post-upgrade-cta-content,
.gh-post-upgrade-cta {
    display: flex;
    flex-direction: column;
    align-items: center;
    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;
    text-align: center;
    width: 100%;
    color: #ffffff;
    font-size: 16px;
}

.gh-post-upgrade-cta-content {
    border-radius: 8px;
    padding: 40px 4vw;
}

.gh-post-upgrade-cta h2 {
    color: #ffffff;
    font-size: 28px;
    letter-spacing: -0.2px;
    margin: 0;
    padding: 0;
}

.gh-post-upgrade-cta p {
    margin: 20px 0 0;
    padding: 0;
}

.gh-post-upgrade-cta small {
    font-size: 16px;
    letter-spacing: -0.2px;
}

.gh-post-upgrade-cta a {
    color: #ffffff;
    cursor: pointer;
    font-weight: 500;
    box-shadow: none;
    text-decoration: underline;
}

.gh-post-upgrade-cta a:hover {
    color: #ffffff;
    opacity: 0.8;
    box-shadow: none;
    text-decoration: underline;
}

.gh-post-upgrade-cta a.gh-btn {
    display: block;
    background: #ffffff;
    text-decoration: none;
    margin: 28px 0 0;
    padding: 8px 18px;
    border-radius: 4px;
    font-size: 16px;
    font-weight: 600;
}

.gh-post-upgrade-cta a.gh-btn:hover {
    opacity: 0.92;
}</style>
    <script defer src="https://cdn.jsdelivr.net/ghost/sodo-search@~1.8/umd/sodo-search.min.js" data-key="e411fdfa6f54398669f416d1f0" data-styles="https://cdn.jsdelivr.net/ghost/sodo-search@~1.8/umd/main.css" data-sodo-search="https://langchain-blog.ghost.io/" data-locale="en" crossorigin="anonymous"></script>
    
    <link href="https://www.blog.langchain.com/webmentions/receive/" rel="webmention">
    <script defer src="/public/cards.min.js?v=b17a0306be"></script>
    <link rel="stylesheet" type="text/css" href="/public/cards.min.css?v=b17a0306be">
    <script defer src="/public/member-attribution.min.js?v=b17a0306be"></script>
    <script defer src="/public/ghost-stats.min.js?v=b17a0306be" data-stringify-payload="false" data-datasource="analytics_events" data-storage="localStorage" data-host="https://www.blog.langchain.com/.ghost/analytics/api/v1/page_hit"  tb_site_uuid="97889716-a759-46f4-b63f-4f5c46a13333" tb_post_uuid="31ca0ab1-5614-4965-93f3-b1348c0d04ac" tb_post_type="post" tb_member_uuid="undefined" tb_member_status="undefined"></script><style>:root {--ghost-accent-color: #1c3b3b;}</style>
    <!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-PKJ3R6D8');</script>
<!-- End Google Tag Manager -->

<script defer data-domain="blog.langchain.dev" src="https://plausible.io/js/script.js"></script>

<style>
  .nav-signin { /* Replace .nav-signin with the actual class or id */
    display: none !important;
  }
</style>


<style>
@media (min-width: 62.5em) {
    .article-header__figure {
        aspect-ratio: 16/9;
    }

</style>

<meta name="google-site-verification" content="wr4UCEYzUuA1lg3MF2RFoRdF7AxRujOawehorKfkZ5M" />
</head>

<body class="post-template">

    <a class="skip-link visually-hidden-focusable" href="#main">Skip to content</a>

    <div class="site">

        <header id="site-header" class="site-header">
    <span class="site-header__bg"></span>

    <div class="site-header__container container">
        <button
            class="site-header__hamburger"
            data-site-action-trigger="navigation"
            aria-label="Open Menu"
            aria-expanded="false"
            aria-controls="site-actions-navigation">
            <span></span>
        </button>

        <a href="https://www.blog.langchain.com" rel="home" class="site-header__logo">
                <img class="site-header__logo-image" data-logo-color-scheme="default" src="https://www.blog.langchain.com/content/images/2024/03/LangChain-logo.png" alt="LangChain Blog">
        </a>

        <div id="site-actions-navigation" class="site-navigation">
            <div class="site-navigation__inner">
                        <nav class="nav-classic">
            <ul class="nav-classic__menu">
                 
                    <li class="nav-classic__menu-item">
                        <a class="nav-classic__menu-link" href="https://www.langchain.com/">
                            <span class="nav-classic__menu-title">Website</span>
                        </a>
                    </li>
                 
                 
                    <li class="nav-classic__menu-item">
                        <a class="nav-classic__menu-link" href="https://docs.langchain.com/">
                            <span class="nav-classic__menu-title">Docs</span>
                        </a>
                    </li>
                 
                 
                    <li class="nav-classic__menu-item">
                        <a class="nav-classic__menu-link" href="https://www.blog.langchain.com/tag/in-the-loop/">
                            <span class="nav-classic__menu-title">Harrison&#x27;s Hot Takes</span>
                        </a>
                    </li>
                 
                 
                    <li class="nav-classic__menu-item">
                        <a class="nav-classic__menu-link" href="https://smith.langchain.com/">
                            <span class="nav-classic__menu-title">Try LangSmith</span>
                        </a>
                    </li>
                 
            </ul>
        </nav>

                    <div class="site-account">
                <a class="site-account__link" href="#/portal/signin" data-portal="signin">Sign in</a>
                <a class="site-account__button button" data-btn-size="small" href="#/portal/signup" data-portal="signup">Subscribe</a>
    </div>
                            </div>
        </div>

        <button
            class="site-header__search-trigger"
            aria-label="Open Search"
            data-ghost-search>
            <span></span>
        </button>
    </div>

    <div class="site-actions">
        <span class="site-actions__backdrop" data-close-site-actions></span>
        <span class="site-actions__bg"></span>


    </div>

</header>

        <main id="main" class="site-main">
            

<article class="article post featured">

    <header class="article-header section" data-layout-grid="custom" data-theme="highlight" data-section="first" data-has-featured-image="true">
        <figure class="article-header__figure">
            <img class="article-header__image"
                width="16" height="9"
                src="/content/images/size/w760/format/webp/2025/10/Context-Engineering.png"
                srcset="/content/images/size/w360/format/webp/2025/10/Context-Engineering.png 360w,/content/images/size/w480/format/webp/2025/10/Context-Engineering.png 480w,/content/images/size/w760/format/webp/2025/10/Context-Engineering.png 760w,/content/images/size/w990/format/webp/2025/10/Context-Engineering.png 990w,/content/images/size/w1248/format/webp/2025/10/Context-Engineering.png 1248w,/content/images/size/w1520/format/webp/2025/10/Context-Engineering.png 1520w"
                sizes="(min-width: 1280px) 580px, (min-width: 1000px) calc(50vw - 60px), 100vw"
                loading="eager"
                alt="Context Engineering"
                onload="this.setAttribute('data-loaded', true)">
        </figure>
        <div class="article-header__content">
            <h1 class="article-header__title">Context Engineering</h1>
            <div class="article-header__footer">
                <span class="article-header__meta article-header__meta--read-time">11 min read</span>
                <time class="article-header__meta article-header__meta--date" datetime="2025-07-02">Jul 2, 2025</time>
            </div>
        </div>
    </header>

    <div class="article-main section" data-canvas-grid="content">
        <div class="article-content" data-canvas-grid="content" data-canvas-grid-self="full">
            <h3 id="tldr">TL;DR</h3><p>Agents need context to perform tasks. Context engineering is the art and science of filling the context window with just the right information at each step of an agent’s trajectory. In this post, we break down some common strategies — <strong>write, select, compress, and isolate —</strong> for context engineering by reviewing various popular agents and papers. We then explain how LangGraph is designed to support them! </p><p><strong>Also, see our video on context engineering </strong><a href="https://youtu.be/4GiqzUHD5AA?ref=blog.langchain.com"><strong>here</strong></a><strong>.</strong></p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://www.blog.langchain.com/content/images/2025/07/image.png" class="kg-image" alt="" loading="lazy" width="2000" height="712" srcset="https://www.blog.langchain.com/content/images/size/w600/2025/07/image.png 600w, https://www.blog.langchain.com/content/images/size/w1000/2025/07/image.png 1000w, https://www.blog.langchain.com/content/images/size/w1600/2025/07/image.png 1600w, https://www.blog.langchain.com/content/images/2025/07/image.png 2048w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">General categories of context engineering</span></figcaption></figure><h3 id="context-engineering">Context Engineering</h3><p>As Andrej Karpathy puts it, LLMs are like a <a href="https://www.youtube.com/watch?si=-aKY-x57ILAmWTdw&t=620&v=LCEmiRjPEtQ&feature=youtu.be&ref=blog.langchain.com">new kind of operating system</a>. The LLM is like the CPU and its <a href="https://docs.anthropic.com/en/docs/build-with-claude/context-windows?ref=blog.langchain.com">context window</a> is like the RAM, serving as the model’s working memory. Just like RAM, the LLM context window has limited <a href="https://lilianweng.github.io/posts/2023-06-23-agent/?ref=blog.langchain.com">capacity</a> to handle various sources of context. And just as an operating system curates what fits into a CPU’s RAM, we can think about “context engineering” playing a similar role. <a href="https://x.com/karpathy/status/1937902205765607626?ref=blog.langchain.com">Karpathy summarizes this well</a>:</p><blockquote><em>[Context engineering is the] ”…delicate art and science of filling the context window with just the right information for the next step.”</em></blockquote><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://www.blog.langchain.com/content/images/2025/07/image-1.png" class="kg-image" alt="" loading="lazy" width="1532" height="1038" srcset="https://www.blog.langchain.com/content/images/size/w600/2025/07/image-1.png 600w, https://www.blog.langchain.com/content/images/size/w1000/2025/07/image-1.png 1000w, https://www.blog.langchain.com/content/images/2025/07/image-1.png 1532w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">Context types commonly used in LLM applications</span></figcaption></figure><p>What are the types of context that we need to manage when building LLM applications? Context engineering as an <a href="https://x.com/dexhorthy/status/1933283008863482067?ref=blog.langchain.com">umbrella</a> that applies across a few different context types:</p><ul><li><strong>Instructions</strong> – prompts, memories, few‑shot examples, tool descriptions, etc</li><li><strong>Knowledge</strong> – facts, memories, etc</li><li><strong>Tools</strong> – feedback from tool calls</li></ul><h3 id="context-engineering-for-agents">Context Engineering for Agents</h3><p>This year, interest in <a href="https://www.anthropic.com/engineering/building-effective-agents?ref=blog.langchain.com">agents</a> has grown tremendously as LLMs get better at <a href="https://platform.openai.com/docs/guides/reasoning?api-mode=responses&ref=blog.langchain.com">reasoning</a> and <a href="https://www.anthropic.com/engineering/building-effective-agents?ref=blog.langchain.com">tool calling</a>. <a href="https://www.anthropic.com/engineering/building-effective-agents?ref=blog.langchain.com">Agents</a> interleave <a href="https://www.anthropic.com/engineering/building-effective-agents?ref=blog.langchain.com">LLM invocations and tool calls</a>, often for <a href="https://www.blog.langchain.com/introducing-ambient-agents/">long-running tasks</a>. Agents interleave <a href="https://www.anthropic.com/engineering/building-effective-agents?ref=blog.langchain.com">LLM calls and tool calls</a>, using tool feedback to decide the next step.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://www.blog.langchain.com/content/images/2025/07/image-2.png" class="kg-image" alt="" loading="lazy" width="1415" height="581" srcset="https://www.blog.langchain.com/content/images/size/w600/2025/07/image-2.png 600w, https://www.blog.langchain.com/content/images/size/w1000/2025/07/image-2.png 1000w, https://www.blog.langchain.com/content/images/2025/07/image-2.png 1415w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">Agents interleave</span><a href="https://www.anthropic.com/engineering/building-effective-agents?ref=blog.langchain.com" rel="noopener noreferrer"><span style="white-space: pre-wrap;"> LLM calls and</span></a><a href="https://www.anthropic.com/engineering/building-effective-agents?ref=blog.langchain.com" rel="noopener noreferrer"><span style="white-space: pre-wrap;"> tool calls</span></a><span style="white-space: pre-wrap;">, using tool feedback to decide the next step</span></figcaption></figure><p>However, long-running tasks and accumulating feedback from tool calls mean that agents often utilize a large number of tokens. This can cause numerous problems: it can <a href="https://cognition.ai/blog/kevin-32b?ref=blog.langchain.com">exceed the size of the context window</a>, balloon cost / latency, or degrade agent performance. Drew Breunig <a href="https://www.dbreunig.com/2025/06/22/how-contexts-fail-and-how-to-fix-them.html?ref=blog.langchain.com">nicely outlined</a> a number of specific ways that longer context can cause perform problems, including:</p><ul><li><a href="https://www.dbreunig.com/2025/06/22/how-contexts-fail-and-how-to-fix-them.html?ref=blog.langchain.com#context-poisoning">Context Poisoning: When a hallucination makes it into the context</a></li><li><a href="https://www.dbreunig.com/2025/06/22/how-contexts-fail-and-how-to-fix-them.html?ref=blog.langchain.com#context-distraction">Context Distraction: When the context overwhelms the training</a></li><li><a href="https://www.dbreunig.com/2025/06/22/how-contexts-fail-and-how-to-fix-them.html?ref=blog.langchain.com#context-confusion">Context Confusion: When superfluous context influences the response</a></li><li><a href="https://www.dbreunig.com/2025/06/22/how-contexts-fail-and-how-to-fix-them.html?ref=blog.langchain.com#context-clash">Context Clash: When parts of the context disagree</a></li></ul><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://www.blog.langchain.com/content/images/2025/07/image-3.png" class="kg-image" alt="" loading="lazy" width="1319" height="722" srcset="https://www.blog.langchain.com/content/images/size/w600/2025/07/image-3.png 600w, https://www.blog.langchain.com/content/images/size/w1000/2025/07/image-3.png 1000w, https://www.blog.langchain.com/content/images/2025/07/image-3.png 1319w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">Context from tool calls accumulates over multiple agent turns</span></figcaption></figure><p>With this in mind, <a href="https://cognition.ai/blog/dont-build-multi-agents?ref=blog.langchain.com">Cognition</a> called out the importance of context engineering:</p><blockquote><em>“Context engineering” … is effectively the #1 job of engineers building AI agents.</em></blockquote><p><a href="https://www.anthropic.com/engineering/built-multi-agent-research-system?ref=blog.langchain.com">Anthropic</a> also laid it out clearly:</p><blockquote><em>Agents often engage in conversations spanning hundreds of turns, requiring careful context management strategies.</em></blockquote><p>So, how are people tackling this challenge today? We group common strategies for agent context engineering into four buckets — <strong>write, select, compress, and isolate —</strong> and give examples of each from review of some popular agent products and papers. We then explain how LangGraph is designed to support them!</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://www.blog.langchain.com/content/images/2025/07/image-4.png" class="kg-image" alt="" loading="lazy" width="2000" height="712" srcset="https://www.blog.langchain.com/content/images/size/w600/2025/07/image-4.png 600w, https://www.blog.langchain.com/content/images/size/w1000/2025/07/image-4.png 1000w, https://www.blog.langchain.com/content/images/size/w1600/2025/07/image-4.png 1600w, https://www.blog.langchain.com/content/images/2025/07/image-4.png 2048w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">General categories of context engineering</span></figcaption></figure><h3 id="write-context">Write Context</h3><p><em>Writing context means saving it outside the context window to help an agent perform a task.</em></p><p><strong>Scratchpads</strong></p><p>When humans solve tasks, we take notes and remember things for future, related tasks. Agents are also gaining these capabilities! Note-taking via a “<a href="https://www.anthropic.com/engineering/claude-think-tool?ref=blog.langchain.com">scratchpad</a>” is one approach to persist information while an agent is performing a task. The idea is to save information outside of the context window so that it’s available to the agent. <a href="https://www.anthropic.com/engineering/built-multi-agent-research-system?ref=blog.langchain.com">Anthropic’s multi-agent researcher</a> illustrates a clear example of this:</p><blockquote><em>The LeadResearcher begins by thinking through the approach and saving its plan to Memory to persist the context, since if the context window exceeds 200,000 tokens it will be truncated and it is important to retain the plan.</em></blockquote><p>Scratchpads can be implemented in a few different ways. They can be a <a href="https://www.anthropic.com/engineering/claude-think-tool?ref=blog.langchain.com">tool call</a> that simply <a href="https://github.com/modelcontextprotocol/servers/tree/main/src/filesystem?ref=blog.langchain.com">writes to a file</a>. They can also be a field in a runtime <a href="https://langchain-ai.github.io/langgraph/concepts/low_level/?ref=blog.langchain.com#state">state object</a> that persists during the session. In either case, scratchpads let agents save useful information to help them accomplish a task.</p><p><strong>Memories</strong></p><p>Scratchpads help agents solve a task within a given session (or <a href="https://langchain-ai.github.io/langgraph/concepts/persistence/?ref=blog.langchain.com#threads">thread</a>), but sometimes agents benefit from remembering things across <em>many</em> sessions! <a href="https://arxiv.org/abs/2303.11366?ref=blog.langchain.com">Reflexion</a> introduced the idea of reflection following each agent turn and re-using these self-generated memories. <a href="https://ar5iv.labs.arxiv.org/html/2304.03442?ref=blog.langchain.com">Generative Agents</a> created memories synthesized periodically from collections of past agent feedback.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://www.blog.langchain.com/content/images/2025/07/image-5.png" class="kg-image" alt="" loading="lazy" width="1504" height="920" srcset="https://www.blog.langchain.com/content/images/size/w600/2025/07/image-5.png 600w, https://www.blog.langchain.com/content/images/size/w1000/2025/07/image-5.png 1000w, https://www.blog.langchain.com/content/images/2025/07/image-5.png 1504w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">An LLM can be used to update or create memories</span></figcaption></figure><p>These concepts made their way into popular products like <a href="https://help.openai.com/en/articles/8590148-memory-faq?ref=blog.langchain.com">ChatGPT</a>, <a href="https://forum.cursor.com/t/0-51-memories-feature/98509?ref=blog.langchain.com">Cursor</a>, and <a href="https://docs.windsurf.com/windsurf/cascade/memories?ref=blog.langchain.com">Windsurf</a>, which all have mechanisms to auto-generate long-term memories that can persist across sessions based on user-agent interactions.</p><h3 id="select-context">Select Context</h3><p><em>Selecting context means pulling it into the context window to help an agent perform a task.</em></p><p><strong>Scratchpad</strong></p><p>The mechanism for selecting context from a scratchpad depends upon how the scratchpad is implemented. If it’s a <a href="https://www.anthropic.com/engineering/claude-think-tool?ref=blog.langchain.com">tool</a>, then an agent can simply read it by making a tool call. If it’s part of the agent’s runtime state, then the developer can choose what parts of state to expose to an agent each step. This provides a fine-grained level of control for exposing scratchpad context to the LLM at later turns.</p><p><strong>Memories</strong></p><p>If agents have the ability to save memories, they also need the ability to select memories relevant to the task they are performing. This can be useful for a few reasons. Agents might select few-shot examples (<a href="https://langchain-ai.github.io/langgraph/concepts/memory/?ref=blog.langchain.com#memory-types">episodic</a> <a href="https://arxiv.org/pdf/2309.02427?ref=blog.langchain.com">memories</a>) for examples of desired behavior, instructions (<a href="https://langchain-ai.github.io/langgraph/concepts/memory/?ref=blog.langchain.com#memory-types">procedural</a> <a href="https://arxiv.org/pdf/2309.02427?ref=blog.langchain.com">memories</a>) to steer behavior, or facts (<a href="https://langchain-ai.github.io/langgraph/concepts/memory/?ref=blog.langchain.com#memory-types">semantic</a> <a href="https://arxiv.org/pdf/2309.02427?ref=blog.langchain.com">memories</a>) for task-relevant context.</p><figure class="kg-card kg-image-card"><img src="https://www.blog.langchain.com/content/images/2025/07/image-6.png" class="kg-image" alt="" loading="lazy" width="1612" height="524" srcset="https://www.blog.langchain.com/content/images/size/w600/2025/07/image-6.png 600w, https://www.blog.langchain.com/content/images/size/w1000/2025/07/image-6.png 1000w, https://www.blog.langchain.com/content/images/size/w1600/2025/07/image-6.png 1600w, https://www.blog.langchain.com/content/images/2025/07/image-6.png 1612w" sizes="(min-width: 720px) 720px"></figure><p>One challenge is ensuring that relevant memories are selected. Some popular agents simply use a narrow set of files that are <em>always</em> pulled into context. For example, many code agent use specific files to save instructions (”procedural” memories) or, in some cases, examples (”episodic” memories). Claude Code uses <a href="http://claude.md/?ref=blog.langchain.com"><code>CLAUDE.md</code></a>. <a href="https://docs.cursor.com/context/rules?ref=blog.langchain.com">Cursor</a> and <a href="https://windsurf.com/editor/directory?ref=blog.langchain.com">Windsurf</a> use rules files. </p><p>But, if an agent is storing a larger <a href="https://langchain-ai.github.io/langgraph/concepts/memory/?ref=blog.langchain.com#collection">collection</a> of facts and / or relationships (e.g., <a href="https://langchain-ai.github.io/langgraph/concepts/memory/?ref=blog.langchain.com#memory-types">semantic</a> memories), selection is harder. <a href="https://help.openai.com/en/articles/8590148-memory-faq?ref=blog.langchain.com">ChatGPT</a> is a good example of a popular product that stores and selects from a large collection of user-specific memories.</p><p>Embeddings and / or <a href="https://arxiv.org/html/2501.13956v1?ref=blog.langchain.com#:~:text=In%20Zep%2C%20memory%20is%20powered,subgraph%2C%20and%20a%20community%20subgraph">knowledge</a> <a href="https://neo4j.com/blog/developer/graphiti-knowledge-graph-memory/?ref=blog.langchain.com#:~:text=changes%20since%20updates%20can%20trigger,and%20holistic%20memory%20for%20agentic">graphs</a> for memory indexing are commonly used to assist with selection. Still, memory selection is challenging.  At the AIEngineer World’s Fair, <a href="https://simonwillison.net/2025/Jun/6/six-months-in-llms/?ref=blog.langchain.com">Simon Willison&nbsp;shared</a> an example of selection gone wrong: ChatGPT fetched his location from memories and unexpectedly injected it into a requested image. This type of unexpected or undesired memory retrieval can make some users feel like the context window “<em>no longer belongs to them</em>”! </p><p><strong>Tools</strong></p><p>Agents use tools, but can become overloaded if they are provided with too many. This is often because the tool descriptions overlap, causing model confusion about which tool to use. One approach is<a href="https://arxiv.org/abs/2410.14594?ref=blog.langchain.com"> to apply RAG (retrieval augmented generation) to tool descriptions</a> in order to fetch only the most relevant tools for a task. Some <a href="https://arxiv.org/abs/2505.03275?ref=blog.langchain.com">recent papers</a> have shown that this improve tool selection accuracy by 3-fold.</p><p><strong>Knowledge</strong></p><p><a href="https://github.com/langchain-ai/rag-from-scratch?ref=blog.langchain.com">RAG</a> is a rich topic and it<a href="https://x.com/_mohansolo/status/1899630246862966837?ref=blog.langchain.com"> can be a central context engineering challenge</a>. Code agents are some of the best examples of RAG in large-scale production. Varun from Windsurf captures some of these challenges well:</p><blockquote><em>Indexing code ≠ context retrieval … [We are doing indexing &amp; embedding search … [with] AST parsing code and chunking along semantically meaningful boundaries … embedding search becomes unreliable as a retrieval heuristic as the size of the codebase grows … we must rely on a combination of techniques like grep/file search, knowledge graph based retrieval, and … a re-ranking step where [context] is ranked in order of relevance.</em></blockquote><h3 id="compressing-context">Compressing Context</h3><p><em>Compressing context involves retaining only the tokens required to perform a task.</em></p><p><strong>Context Summarization</strong></p><p>Agent interactions can span <a href="https://www.anthropic.com/engineering/built-multi-agent-research-system?ref=blog.langchain.com">hundreds of turns</a> and use token-heavy tool calls. Summarization is one common way to manage these challenges. If you’ve used Claude Code, you’ve seen this in action. Claude Code runs “<a href="https://docs.anthropic.com/en/docs/claude-code/costs?ref=blog.langchain.com">auto-compact</a>” after you exceed 95% of the context window and it will summarize the full trajectory of user-agent interactions. This type of compression across an <a href="https://langchain-ai.github.io/langgraph/concepts/memory/?ref=blog.langchain.com#manage-short-term-memory">agent trajectory</a> can use various strategies such as <a href="https://arxiv.org/pdf/2308.15022?ref=blog.langchain.com#:~:text=the%20retrieved%20utterances%20capture%20the,based%203">recursive</a> or <a href="https://alignment.anthropic.com/2025/summarization-for-monitoring/?ref=blog.langchain.com#:~:text=We%20addressed%20these%20issues%20by,of%20our%20computer%20use%20capability">hierarchical</a> summarization.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://www.blog.langchain.com/content/images/2025/07/image-7.png" class="kg-image" alt="" loading="lazy" width="1584" height="636" srcset="https://www.blog.langchain.com/content/images/size/w600/2025/07/image-7.png 600w, https://www.blog.langchain.com/content/images/size/w1000/2025/07/image-7.png 1000w, https://www.blog.langchain.com/content/images/2025/07/image-7.png 1584w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">A few places where summarization can be applied</span></figcaption></figure><p>It can also be useful to <a href="https://github.com/langchain-ai/open_deep_research/blob/e5a5160a398a3699857d00d8569cb7fd0ac48a4f/src/open_deep_research/utils.py?ref=blog.langchain.com#L1407">add summarization</a> at specific points in an agent’s design. For example, it can be used to post-process certain tool calls (e.g., token-heavy search tools). As a second example, <a href="https://cognition.ai/blog/dont-build-multi-agents?ref=blog.langchain.com#a-theory-of-building-long-running-agents">Cognition</a> mentioned summarization at agent-agent boundaries to reduce tokens during knowledge hand-off. Summarization can be a challenge if specific events or decisions need to be captured. <a href="https://cognition.ai/blog/dont-build-multi-agents?ref=blog.langchain.com#a-theory-of-building-long-running-agents">Cognition</a> uses a fine-tuned model for this, which underscores how much work can go into this step.</p><p><strong>Context Trimming</strong></p><p>Whereas summarization typically uses an LLM to distill the most relevant pieces of context, trimming can often filter or, as Drew Breunig points out, “<a href="https://www.dbreunig.com/2025/06/26/how-to-fix-your-context.html?ref=blog.langchain.com">prune</a>” context. This can use hard-coded heuristics like removing <a href="https://python.langchain.com/docs/how_to/trim_messages/?ref=blog.langchain.com">older messages</a> from a list. Drew also mentions <a href="https://arxiv.org/abs/2501.16214?ref=blog.langchain.com">Provence</a>, a trained context pruner for Question-Answering.</p><h3 id="isolating-context">Isolating Context</h3><p><em>Isolating context involves splitting it up to help an agent perform a task.</em></p><p><strong>Multi-agent</strong></p><p>One of the most popular ways to isolate context is to split it across sub-agents. A motivation for the OpenAI <a href="https://github.com/openai/swarm?ref=blog.langchain.com">Swarm</a> library was <a href="https://openai.github.io/openai-agents-python/ref/agent/?ref=blog.langchain.com">separation of concerns</a>, where a team of agents can handle specific sub-tasks. Each agent has a specific set of tools, instructions, and its own context window.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://www.blog.langchain.com/content/images/2025/07/image-8.png" class="kg-image" alt="" loading="lazy" width="1262" height="686" srcset="https://www.blog.langchain.com/content/images/size/w600/2025/07/image-8.png 600w, https://www.blog.langchain.com/content/images/size/w1000/2025/07/image-8.png 1000w, https://www.blog.langchain.com/content/images/2025/07/image-8.png 1262w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">Split context across multiple agents</span></figcaption></figure><p>Anthropic’s <a href="https://www.anthropic.com/engineering/built-multi-agent-research-system?ref=blog.langchain.com">multi-agent researcher</a> makes a case for this: many agents with isolated contexts outperformed single-agent, largely because each subagent context window can be allocated to a more narrow sub-task. As the blog said:</p><blockquote><em>[Subagents operate] in parallel with their own context windows, exploring different aspects of the question simultaneously.</em></blockquote><p>Of course, the challenges with multi-agent include token use (e.g., up to <a href="https://www.anthropic.com/engineering/built-multi-agent-research-system?ref=blog.langchain.com">15× more tokens</a> than chat as reported by Anthropic), the need for careful <a href="https://www.anthropic.com/engineering/built-multi-agent-research-system?ref=blog.langchain.com">prompt engineering</a> to plan sub-agent work, and coordination of sub-agents.</p><p><strong>Context Isolation with Environments</strong></p><p>HuggingFace’s <a href="https://huggingface.co/blog/open-deep-research?ref=blog.langchain.com#:~:text=From%20building%20,it%20can%20still%20use%20it">deep researcher</a> shows another interesting example of context isolation. Most agents use <a href="https://docs.anthropic.com/en/docs/agents-and-tools/tool-use/overview?ref=blog.langchain.com">tool calling APIs</a>, which return JSON objects (tool arguments) that can be passed to tools (e.g., a search API) to get tool feedback (e.g., search results). HuggingFace uses a <a href="https://huggingface.co/papers/2402.01030?ref=blog.langchain.com">CodeAgent</a>, which outputs that contains the desired tool calls. The code then runs in a <a href="https://e2b.dev/?ref=blog.langchain.com">sandbox</a>. Selected context (e.g., return values) from the tool calls is then passed back to the LLM.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://www.blog.langchain.com/content/images/2025/07/image-9.png" class="kg-image" alt="" loading="lazy" width="1532" height="584" srcset="https://www.blog.langchain.com/content/images/size/w600/2025/07/image-9.png 600w, https://www.blog.langchain.com/content/images/size/w1000/2025/07/image-9.png 1000w, https://www.blog.langchain.com/content/images/2025/07/image-9.png 1532w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">Sandboxes can isolate context from the LLM.</span></figcaption></figure><p>This allows context to be isolated from the LLM in the environment. Hugging Face noted that this is a great way to isolate token-heavy objects in particular:</p><blockquote><em>[Code Agents allow for] a better handling of state … Need to store this image / audio / other for later use? No problem, just assign it as a variable </em><a href="https://deepwiki.com/search/i-am-wondering-if-state-that-i_0e153539-282a-437c-b2b0-d2d68e51b873?ref=blog.langchain.com"><em>in your state and you [use it later]</em></a><em>.</em></blockquote><p><strong>State</strong></p><p>It’s worth calling out that an agent’s runtime <a href="https://langchain-ai.github.io/langgraph/concepts/low_level/?ref=blog.langchain.com#state">state object</a> can also be a great way to isolate context. This can serve the same purpose as sandboxing. A state object can be designed with a <a href="https://langchain-ai.github.io/langgraph/concepts/low_level/?ref=blog.langchain.com#schema">schema</a> that has fields that context can be written to. One field of the schema (e.g., <code>messages</code>) can be exposed to the LLM at each turn of the agent, but the schema can isolate information in other fields for more selective use.</p><h3 id="context-engineering-with-langsmith-langgraph">Context Engineering with LangSmith / LangGraph</h3><p>So, how can you apply these ideas? Before you start, there are two foundational pieces that are helpful. First, ensure that you have a way to <a href="https://hamel.dev/blog/posts/evals/?ref=blog.langchain.com">look at your data</a> and track token-usage across your agent. This helps inform where best to apply effort context engineering. <a href="https://docs.smith.langchain.com/?ref=blog.langchain.com">LangSmith</a> is well-suited for agent <a href="https://docs.smith.langchain.com/observability?ref=blog.langchain.com">tracing / observability</a>, and offers a great way to do this. Second,  be sure you have a simple way to test whether context engineering hurts or improve agent performance. LangSmith enables <a href="https://docs.smith.langchain.com/evaluation/tutorials/agents?ref=blog.langchain.com">agent evaluation</a> to test the impact of any context engineering effort.</p><p><strong>Write context</strong></p><p>LangGraph was designed with both thread-scoped (<a href="https://langchain-ai.github.io/langgraph/concepts/memory/?ref=blog.langchain.com#short-term-memory">short-term</a>) and <a href="https://langchain-ai.github.io/langgraph/concepts/memory/?ref=blog.langchain.com#long-term-memory">long-term memory</a>. Short-term memory uses <a href="https://langchain-ai.github.io/langgraph/concepts/persistence/?ref=blog.langchain.com">checkpointing</a> to persist <a href="https://langchain-ai.github.io/langgraph/concepts/low_level/?ref=blog.langchain.com#state">agent state</a> across all steps of an agent. This is extremely useful as a “scratchpad”, allowing you to write information to state and fetch it at any step in your agent trajectory.</p><p>LangGraph’s long-term memory lets you to persist context <em>across many sessions</em> with your agent. It is flexible, allowing you to save small sets of <a href="https://langchain-ai.github.io/langgraph/concepts/memory/?ref=blog.langchain.com#profile">files</a> (e.g., a user profile or rules) or larger <a href="https://langchain-ai.github.io/langgraph/concepts/memory/?ref=blog.langchain.com#collection">collections</a> of memories. In addition, <a href="https://langchain-ai.github.io/langmem/?ref=blog.langchain.com">LangMem</a> provides a broad set of useful abstractions to aid with LangGraph memory management.</p><p><strong>Select context</strong></p><p>Within each node (step) of a LangGraph agent, you can fetch <a href="https://langchain-ai.github.io/langgraph/concepts/low_level/?ref=blog.langchain.com#state">state</a>. This give you fine-grained control over what context you present to the LLM at each agent step. </p><p>In addition, LangGraph’s long-term memory is accessible within each node and supports various types of retrieval (e.g., fetching files as well as <a href="https://langchain-ai.github.io/langgraph/cloud/reference/cli/?ref=blog.langchain.com#adding-semantic-search-to-the-store">embedding-based retrieval on a memory collection).</a> For an overview of long-term memory, see <a href="https://www.deeplearning.ai/short-courses/long-term-agentic-memory-with-langgraph/?ref=blog.langchain.com">our Deeplearning.ai course</a>. And for an entry point to memory applied to a specific agent, see our <a href="https://academy.langchain.com/courses/ambient-agents?ref=blog.langchain.com">Ambient Agents</a> course. This shows how to use LangGraph memory in a long-running agent that can manage your email and learn from your feedback.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://www.blog.langchain.com/content/images/2025/07/image-10.png" class="kg-image" alt="" loading="lazy" width="2000" height="454" srcset="https://www.blog.langchain.com/content/images/size/w600/2025/07/image-10.png 600w, https://www.blog.langchain.com/content/images/size/w1000/2025/07/image-10.png 1000w, https://www.blog.langchain.com/content/images/size/w1600/2025/07/image-10.png 1600w, https://www.blog.langchain.com/content/images/2025/07/image-10.png 2048w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">Email agent with user feedback and long-term memory</span></figcaption></figure><p>For tool selection, the <a href="https://github.com/langchain-ai/langgraph-bigtool?ref=blog.langchain.com">LangGraph Bigtool</a> library is a great way to apply semantic search over tool descriptions. This helps select the most relevant tools for a task when working with a large collection of tools. Finally, we have several <a href="https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_agentic_rag/?ref=blog.langchain.com">tutorials and videos</a> that show how to use various types of RAG with LangGraph.</p><p><strong>Compressing context</strong></p><p>Because LangGraph <a href="https://www.blog.langchain.com/how-to-think-about-agent-frameworks/">is a low-level orchestration framework</a>, you <a href="https://www.youtube.com/watch?v=aHCDrAbH_go&ref=blog.langchain.com">lay out your agent as a set of nodes</a>, <a href="https://www.blog.langchain.com/how-to-think-about-agent-frameworks/">define</a> the logic within each one, and define an state object that is passed between them. This control offers several ways to compress context.</p><p>One common approach is to use a message list as your agent state and <a href="https://langchain-ai.github.io/langgraph/how-tos/memory/add-memory/?ref=blog.langchain.com#manage-short-term-memory">summarize or trim</a> it periodically using <a href="https://langchain-ai.github.io/langgraph/how-tos/memory/add-memory/?ref=blog.langchain.com#manage-short-term-memory">a few built-in utilities</a>. However, you can also add logic to post-process <a href="https://github.com/langchain-ai/open_deep_research/blob/e5a5160a398a3699857d00d8569cb7fd0ac48a4f/src/open_deep_research/utils.py?ref=blog.langchain.com#L1407">tool calls</a> or work phases of your agent in a few different ways. You can add summarization nodes at specific points or also add summarization logic to your tool calling node in order to compress the output of specific tool calls.</p><p><strong>Isolating context</strong></p><p>LangGraph is designed around a <a href="https://langchain-ai.github.io/langgraph/concepts/low_level/?ref=blog.langchain.com#state">state</a> object, allowing you to specify a state schema and access state at each agent step. For example, you can store context from tool calls in certain fields in state, isolating them from the LLM until that context is required. In addition to state, LangGraph supports use of sandboxes for context isolation. See this <a href="https://github.com/jacoblee93/mini-chat-langchain?tab=readme-ov-file&ref=blog.langchain.com">repo</a> for an example LangGraph agent that uses <a href="https://e2b.dev/?ref=blog.langchain.com">an E2B sandbox</a> for tool calls. See this <a href="https://www.youtube.com/watch?v=FBnER2sxt0w&ref=blog.langchain.com">video</a> for an example of sandboxing using Pyodide where state can be persisted. LangGraph also has a lot of support for building multi-agent architecture, such as the <a href="https://github.com/langchain-ai/langgraph-supervisor-py?ref=blog.langchain.com">supervisor</a> and <a href="https://github.com/langchain-ai/langgraph-swarm-py?ref=blog.langchain.com">swarm</a> libraries. You can <a href="https://www.youtube.com/watch?v=4nZl32FwU-o&ref=blog.langchain.com">see</a> <a href="https://www.youtube.com/watch?v=JeyDrn1dSUQ&ref=blog.langchain.com">these</a> <a href="https://www.youtube.com/watch?v=B_0TNuYi56w&ref=blog.langchain.com">videos</a> for more detail on using multi-agent with LangGraph.</p><h3 id="conclusion">Conclusion</h3><p>Context engineering is becoming a craft that agents builders should aim to master. Here, we covered a few common patterns seen across many popular agents today:</p><ul><li><em>Writing context - saving it outside the context window to help an agent perform a task.</em></li><li><em>Selecting context - pulling it into the context window to help an agent perform a task.</em></li><li><em>Compressing context - retaining only the tokens required to perform a task.</em></li><li><em>Isolating context - splitting it up to help an agent perform a task.</em></li></ul><p>LangGraph makes it easy to implement each of them and LangSmith provides an easy way to test your agent and track context usage. Together, LangGraph and LangGraph enable a virtuous feedback loop for identifying the best opportunity to apply context engineering, implementing it, testing it, and repeating.</p>
        </div>




        <div class="article-newsletter newsletter-box" data-theme="highlight">
            <h3 class="newsletter-box__title meta-title">Join our newsletter</h3>
            <p class="newsletter-box__info">Updates from the LangChain team and community</p>
            <form class="newsletter-box__form" data-members-form="signup" data-theme="reset">
                <div class="newsletter-box__form-field">
                    <label for="newsletter-box-email-input" class="visually-hidden">Enter your email</label>
                    <input id="newsletter-box-email-input" class="newsletter-box__form-input" type="email" name="email" placeholder="Enter your email" required data-members-email>
                    <button class="newsletter-box__form-submit" type="submit">Subscribe</button>
                </div>
                <p class="newsletter-box__message" data-message="loading">Processing your application...</p>
                <p class="newsletter-box__message" data-message="success">Success! Please check your inbox and click the link to confirm your subscription.</p>
                <p class="newsletter-box__message" data-message="error">Sorry, something went wrong. Please try again.</p>
            </form>
        </div>
    </div>

    <footer class="article-footer">
        

    </footer>

</article>


        </main>

        <footer id="site-footer" class="site-footer" data-theme="highlight">


    <div class="site-footer__content" data-canvas-grid="container">

        

        <p class="site-footer__copyright">
            © LangChain Blog 2026
        </p>

    </div>
</footer>

    </div><!-- .site -->

    <script type="module" src="https://www.blog.langchain.com/assets/dist/main.js?v=b17a0306be"></script>

    <!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-PKJ3R6D8"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->

</body>

</html>
